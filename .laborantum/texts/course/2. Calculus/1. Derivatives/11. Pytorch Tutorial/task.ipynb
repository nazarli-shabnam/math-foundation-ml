{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "import json_tricks"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Torch\n",
                "\n",
                "Torch is the main tool for deep learning. Its power is calculating analytical derivatives through insanely complicated graph using the algorithm that is called *backpropagation*\n",
                "\n",
                "In this small tutorial we will learn to use it\n",
                "\n",
                "Below is the code that creates a computational graph of a rather complex function:\n",
                "\n",
                "$\\sum_{k=1}^{100} \\exp(\\sin^2(x) + x ^ 2)$"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = torch.linspace(-1, 1, 100, requires_grad=True)\n",
                "y = torch.sin(x)\n",
                "\n",
                "f = torch.exp(y ** 2 + x ** 2).sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, as we have a value of the function, we can call `.backward()` on the single-valued tensor.\n",
                "\n",
                "This tensor holds the history of how was it created from the variables that require gradient calculation.\n",
                "\n",
                "In our setup, `x` is such a set of variables\n",
                "\n",
                "Before we run `.backward()`, the gradients are empty:"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(x.grad)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let us run `.backward()` and see, what happens:"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f.backward()\n",
                "\n",
                "print(x.grad)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now you can calculate gradients through the graphs of any complexity"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "json_tricks.dump(x.grad.numpy(), '.answer.json')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}